{
    "architectures": [
      "LlamaTTS"
    ],
    "auto_map": {
      "AutoConfig": "configuration_llama_tts.LlamaTTSConfig",
      "AutoModel": "modeling_llama_tts.LlamaTTS"
    },
    "audio_vocab_size": 1100,
    "tts_adapter_hidden_layers": 6,
    "tts_adapter_hidden_size": 1024,
    "tts_adapter_intermediate_size": 2744,
    "tts_adapter_attention_heads": 16,
    "tts_adapter_dropout": 0.0,
    "tts_adapter_attention_dropout": 0.0,
    "boa_token_id": 1,
    "eoa_token_id": 2,
    "llm_path": "/mnt/ceph/huggingface/Llama-3.1-8B",
    "tie_audio_embeddings": true
}